{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import copy\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, random_split, \\\nTensorDataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-28T00:28:09.088812Z","iopub.execute_input":"2023-04-28T00:28:09.089267Z","iopub.status.idle":"2023-04-28T00:28:09.097132Z","shell.execute_reply.started":"2023-04-28T00:28:09.089228Z","shell.execute_reply":"2023-04-28T00:28:09.095264Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self,n_features,hidden_dim):\n        \n        super().__init__()\n        self.hidden_dim=hidden_dim\n        self.n_features=n_features\n        self.hidden=None\n        self.basic_rnn=nn.GRU(self.n_features,\n                             self.hidden_dim,\n                             batch_first=True)\n        \n    def forward(self,x):\n        rnn_out,self.hidden=self.basic_rnn(x)\n        return rnn_out\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:28:09.741029Z","iopub.execute_input":"2023-04-28T00:28:09.741430Z","iopub.status.idle":"2023-04-28T00:28:09.749286Z","shell.execute_reply.started":"2023-04-28T00:28:09.741395Z","shell.execute_reply":"2023-04-28T00:28:09.747617Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"full_seq = (torch.tensor([[-1, -1], [-1, 1], [1, 1], [1, -1]])\n.float()\n.view(1, 4, 2))\nsource_seq = full_seq[:, :2] # first two corners\ntarget_seq = full_seq[:, 2:] # last two corners","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:28:10.419320Z","iopub.execute_input":"2023-04-28T00:28:10.419728Z","iopub.status.idle":"2023-04-28T00:28:10.428823Z","shell.execute_reply.started":"2023-04-28T00:28:10.419693Z","shell.execute_reply":"2023-04-28T00:28:10.427324Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(21)\nencoder = Encoder(n_features=2, hidden_dim=2)\nhidden_seq = encoder(source_seq) # output is N, L, F\nhidden_final = hidden_seq[:, -1:]\n# takes last hidden state\nhidden_final,hidden_seq","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:28:11.062420Z","iopub.execute_input":"2023-04-28T00:28:11.063272Z","iopub.status.idle":"2023-04-28T00:28:11.076207Z","shell.execute_reply.started":"2023-04-28T00:28:11.063222Z","shell.execute_reply":"2023-04-28T00:28:11.074881Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(tensor([[[ 0.3105, -0.5263]]], grad_fn=<SliceBackward0>),\n tensor([[[ 0.0832, -0.0356],\n          [ 0.3105, -0.5263]]], grad_fn=<TransposeBackward1>))"},"metadata":{}}]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    \n    def __init__(self,n_features,hidden_dim):\n        \n        super().__init__()\n        \n        self.hidden_dim=hidden_dim\n        \n        self.n_features=n_features\n        \n        self.hidden=None\n        \n        self.basic_rnn=nn.GRU(self.n_features,\n                             self.hidden_dim,\n                             batch_first=True)\n        self.regression=nn.Linear(self.hidden_dim,\n                                 self.n_features)\n    def init_hidden(self,hidden_seq):\n        \n        hidden_final=hidden_seq[:,-1:]\n        \n        self.hidden=hidden_final.permute(1,0,2)\n        \n    def forward(self,x):\n        \n        batch_first_output , self.hidden=self.basic_rnn(x,self.hidden)\n        \n        last_output=batch_first_output[:,-1:]\n        \n        out=self.regression(last_output)\n        \n        return out.view(-1,1,self.n_features)\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:28:11.770595Z","iopub.execute_input":"2023-04-28T00:28:11.771054Z","iopub.status.idle":"2023-04-28T00:28:11.780346Z","shell.execute_reply.started":"2023-04-28T00:28:11.771015Z","shell.execute_reply":"2023-04-28T00:28:11.779270Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(21)\ndecoder=Decoder(2,2)\n\ndecoder.init_hidden(hidden_seq)\ninputs=source_seq[:,-1:]\n\nprint('Inputs :',inputs)\ntarget_len=2\nfor i in range(target_len):\n    print(f'Hidden : {decoder.hidden}')\n    out=decoder(inputs)\n    print(f'outputs :{out}')\n    inputs=out","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:28:12.583724Z","iopub.execute_input":"2023-04-28T00:28:12.584201Z","iopub.status.idle":"2023-04-28T00:28:12.598549Z","shell.execute_reply.started":"2023-04-28T00:28:12.584149Z","shell.execute_reply":"2023-04-28T00:28:12.596973Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Inputs : tensor([[[-1.,  1.]]])\nHidden : tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\noutputs :tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\nHidden : tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\noutputs :tensor([[[-0.0226,  0.4628]]], grad_fn=<ViewBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initial hidden state will be encoder's final hidden state\ndecoder.init_hidden(hidden_seq)\n# Initial data point is the last element of source sequence\ninputs = source_seq[:, -1:]\n\ntarget_len=2\nfor i in range(target_len):\n    print(f'Hidden : {decoder.hidden}')\n    out=decoder(inputs)\n    print(f'outputs :{out}')\n    inputs=target_seq[:,i:i+1]\n    print(f'i :{target_seq[:,i:i+1]}')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:28:14.023776Z","iopub.execute_input":"2023-04-28T00:28:14.024180Z","iopub.status.idle":"2023-04-28T00:28:14.038851Z","shell.execute_reply.started":"2023-04-28T00:28:14.024147Z","shell.execute_reply":"2023-04-28T00:28:14.037199Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Hidden : tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\noutputs :tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\ni :tensor([[[1., 1.]]])\nHidden : tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\noutputs :tensor([[[0.2265, 0.4529]]], grad_fn=<ViewBackward0>)\ni :tensor([[[ 1., -1.]]])\n","output_type":"stream"}]},{"cell_type":"code","source":"decoder.init_hidden(hidden_seq)\n\ninputs=source_seq[:,-1:]\n\nteacher_forcing_prob=0.5\ntarget_len=2\nfor i in range(target_len):\n    print(f'Hidden state :{decoder.hidden}')\n    out=decoder(inputs)\n    print(f'Output : {out}')\n    \n    if torch.randn(1)<=teacher_forcing_prob:\n        inputs=target_seq[:,i:i+1]\n        \n    else:\n        inputs=out","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:30:45.603932Z","iopub.execute_input":"2023-04-28T00:30:45.604444Z","iopub.status.idle":"2023-04-28T00:30:45.617968Z","shell.execute_reply.started":"2023-04-28T00:30:45.604404Z","shell.execute_reply":"2023-04-28T00:30:45.616508Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Hidden state :tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\nOutput : tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\nHidden state :tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\nOutput : tensor([[[-0.0226,  0.4628]]], grad_fn=<ViewBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"class EncoderDecoder(nn.Module):\n    \n    def __init__(self,\n                encoder,\n                decoder,\n                input_len,\n                target_len,\n                teacher_forcing_prob=0.5):\n        super().__init__()\n        self.encoder=encoder\n        self.decoder=decoder\n        self.input_len=input_len\n        self.target_len=target_len\n        self.teacher_forcing_prob=teacher_forcing_prob\n        self.outputs=None\n        \n    def init_outputs(self,batch_size):\n        print('\\n\\nInitialization of outputs ')\n        device = next(self.parameters()).device\n        # N---->batch_size\n        #L----->target_len\n        #F----->ecnoder_features\n        print(f'\\n\\nBatch_size ->(N) : {batch_size}\\nInput_length ->(L) : {self.target_len} \\nEncoder_feature-->(F) : {self.encoder.n_features}')\n        self.outputs=torch.zeros(batch_size,self.target_len,\n                                 self.encoder.n_features).to(device)\n        \n    def store_outputs(self,i,out):\n        print('\\n\\nStore_outputs')\n        self.outputs[:,i:i+1,:]=out\n        print(f'Full Output : ',out)\n        print('Iteration', i)\n        print(f'Storing output from {i} : {i+1}')\n        print(f'Stored outputs :{self.outputs[:,i:i+1]}')\n        \n    def forward(self,x):\n        print('\\n\\nforward')\n        #splits the data in source and target sequence\n        #the target seq will be empty in testing mode\n        # N,L,F\n        \n        source_seq=x[:,:self.input_len,:]\n        print(f'Source Seq : {source_seq}')\n        target_seq=x[:,self.input_len:,:]\n        print(f'target Seq : {target_seq}')\n        self.init_outputs(x.shape[0])\n        \n        hidden_seq=self.encoder(source_seq)\n        print(f'Hidden_seq Of encoder : {hidden_seq}')\n        self.decoder.init_hidden(hidden_seq)\n        \n        dec_inputs=source_seq[:,-1:,:]\n        print('\\n\\n***************Decoder Iteration******************\\n')\n        for i in range(self.target_len):\n            \n            out=self.decoder(dec_inputs)\n            \n            self.store_outputs(i,out)\n            \n            prob=self.teacher_forcing_prob\n            \n            if not self.training:\n                prob=0\n                \n            if torch.rand(1) <= prob:\n                \n                dec_inputs=target_seq[:,i:i+1,:]\n                print(f'Decoder Ouputs : {target_seq[:,i:i+1,:]}')\n            else:\n                dec_inputs=out\n        \n        return self.outputs\n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:01:52.187782Z","iopub.execute_input":"2023-04-28T01:01:52.188195Z","iopub.status.idle":"2023-04-28T01:01:52.204577Z","shell.execute_reply.started":"2023-04-28T01:01:52.188161Z","shell.execute_reply":"2023-04-28T01:01:52.202878Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"encdec=EncoderDecoder(encoder,\n                     decoder,\n                     input_len=2,\n                     target_len=2,\n                     teacher_forcing_prob=0.5)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:01:52.849229Z","iopub.execute_input":"2023-04-28T01:01:52.850551Z","iopub.status.idle":"2023-04-28T01:01:52.856228Z","shell.execute_reply.started":"2023-04-28T01:01:52.850498Z","shell.execute_reply":"2023-04-28T01:01:52.854859Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"\nencdec.train()\nprint('Output : ',encdec(full_seq))","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:03:16.988275Z","iopub.execute_input":"2023-04-28T01:03:16.989285Z","iopub.status.idle":"2023-04-28T01:03:17.000955Z","shell.execute_reply.started":"2023-04-28T01:03:16.989226Z","shell.execute_reply":"2023-04-28T01:03:16.999527Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"\n\nforward\nSource Seq : tensor([[[-1., -1.],\n         [-1.,  1.]]])\ntarget Seq : tensor([[[ 1.,  1.],\n         [ 1., -1.]]])\n\n\nInitialization of outputs \n\n\nBatch_size ->(N) : 1\nInput_length ->(L) : 2 \nEncoder_feature-->(F) : 2\nHidden_seq Of encoder : tensor([[[ 0.0832, -0.0356],\n         [ 0.3105, -0.5263]]], grad_fn=<TransposeBackward1>)\n\n\n***************Decoder Iteration******************\n\n\n\nStore_outputs\nFull Output :  tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\nIteration 0\nStoring output from 0 : 1\nStored outputs :tensor([[[-0.2339,  0.4702]]], grad_fn=<SliceBackward0>)\n\n\nStore_outputs\nFull Output :  tensor([[[-0.0226,  0.4628]]], grad_fn=<ViewBackward0>)\nIteration 1\nStoring output from 1 : 2\nStored outputs :tensor([[[-0.0226,  0.4628]]], grad_fn=<SliceBackward0>)\nOutput :  tensor([[[-0.2339,  0.4702],\n         [-0.0226,  0.4628]]], grad_fn=<CopySlices>)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}